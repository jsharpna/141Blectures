{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to Data Science\n",
    "\n",
    "## Stats 141B\n",
    "\n",
    "## Lecture 1\n",
    "\n",
    "## Prof. Sharpnack\n",
    "\n",
    "## Lecture slides at http://anson.ucdavis.edu/~jsharpna/141Blectures/lecture1/lecture1.slides.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/datascience.png' width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Voice from industry\n",
    "\n",
    "**What is a data scientist?**\n",
    "\n",
    "“essential skills to me are things like sound probabilistic reasoning, statistics, and rational decision theory. I like candidates who can think hard about what to measure, are cognizant of issues related to sampling bias, hypothesis testing, who understand Bayesian updating, understand something about causal modeling, and have taken some undergrad economics. Also, curiosity and a desire to dive into the data is important.”\n",
    "\n",
    "-Ted Sandler, Amazon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Voice from industry\n",
    "\n",
    "1. know how to be productive on linux (b,c)\n",
    "2. know how to do scientific programming in python and/or R, preferably both (a,b)\n",
    "3. know how to do data munging with unix tools or with Python/Perl (b)\n",
    "4. have some experience with databases and SQL (b)\n",
    "5. have experience coding in a statically typed language like Java/C++/Scala \n",
    "6. will have done some work with map-reduce, PIG, or Spark (c)\n",
    "7. have done some data visualization projects (a,b)\n",
    "\n",
    "-Ted Sandler, Amazon\n",
    "\n",
    "Learned in (a) 141A, (b) 141B, (c) 141C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Art and science of understanding data\n",
    "\n",
    "**Typical statistical process:**\n",
    "\n",
    "1. Come up with a model for the data (talk to domain scientists)\n",
    "2. Determine an algorithm to estimate modelling parameters\n",
    "3. Run algorithm\n",
    "4. Inference/confidence interval for parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Art and science of understanding data\n",
    "\n",
    "**Increased data prevalence**\n",
    "\n",
    "> *Old way:* designed experiments to answer specific questions in controlled environment\n",
    "\n",
    "> *New way:* Ask questions and go find/extract data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Art and science of understanding data\n",
    "\n",
    "**Real life data science process:**\n",
    "1. Broad question or curiosity\n",
    "2. Find and extract relevant data\n",
    "3. Exploratory data analysis and visualization\n",
    "4. Formulate specific questions\n",
    "5. Use statistical/machine learning methods\n",
    "6. Communicate your findings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Purpose of this course\n",
    "\n",
    "1. Get familiar with open source technology for data science\n",
    "2. Get confident with data munging (data science by any means necessary)\n",
    "3. Explore principles of data processing and communication\n",
    "4. Learn collaborative/software development tools (versioning systems)\n",
    "5. Witness interplay between statistics and data processing/visualization\n",
    "6. Start your data science portfolio\n",
    "7. Make you feel alive again, if just for a little while\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jobs where these skills can help\n",
    "\n",
    "Everything…\n",
    "\n",
    "1. Statistician\n",
    "2. Big data (google / amazon / etc.)\n",
    "3. Insurance / biotech / sociology / physics / etc.\n",
    "4. Startup\n",
    "5. Data journalism\n",
    "6. Management / marketing / sales\n",
    "7. Public policy / politics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This course\n",
    "\n",
    "1. 6-8 Assignments (50 - 60% of grade)\n",
    "2. 1 Final Project (40% of grade)\n",
    "3. 2 TAs: Lifeng Wei, Chi Po Choi\n",
    "4. Communicate with eachother, get/turn in assignments, see announcements on *Canvas*\n",
    "5. Email me at prof.jsharpna@gmail.com\n",
    "6. Office Hours starting next week: time TBD\n",
    "7. The book: http://anson.ucdavis.edu/~jsharpna/DSBook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Job Market Analysis\n",
    "\n",
    "### by Jiewei Chen and Da Xue\n",
    "\n",
    "### Stats 141B (winter 2017) final project\n",
    "\n",
    "- used Indeed.com api\n",
    "- Compared statistics jobs to chemical engineering\n",
    "- Extracted qualifications, salaries, etc. from job descriptions\n",
    "- project at https://celinechen0211.github.io/JobMarket/jobmarket.html\n",
    "- the following is reproduced from their final project with their permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this part, we analyzed the __skill set__, __degree requirement__, __salary level__ and __distribution of jobs__ for different majors. <br>\n",
    "\n",
    "To get the __skill set__ required for different majors, we did natural language processing on the posts of the jobs, and extracted the top skills that are related to different majors. Further analysis was also done by comparing those skill sets.\n",
    "\n",
    "The __degree requirement__ were compared across different majors and different job types (internship and fulltime).\n",
    "\n",
    "The __annual salary levels__ are compared across different majors. They were extracted from the job discription text by using natual language processing and regular expression. Further analysis on the skill requiremnt of different salary levels for statistics major was also performed. \n",
    "\n",
    "The __distribution of company locations__ were extracted across different majors and geographical visuallization techiniques were used.\n",
    "\n",
    "| Information      | Methodology                         |\n",
    "|------------------|-------------------------------------|\n",
    "|Skill set         | Natural language processing / Graphs|\n",
    "|Degree requirement| Natural language processing / Graphs|\n",
    "|Salary            | Regular expression / Graphs         |\n",
    "|Job market demand | Geographical data analysis / Data visualization|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   # sklearn --- primer machine learning package\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from matplotlib_venn import venn3\n",
    "from wordcloud import WordCloud\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.patches as mpatches\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def diction_qual(files):\n",
    "    \"\"\"\n",
    "    Returns a dictionary from lemmata to document ids containing that lemma\n",
    "    Input is a list of job description text\n",
    "    Output is a dictionary with lemmata as key and document ids as values\n",
    "    \"\"\"\n",
    "    textd = {} \n",
    "    for i in range(len(files)):\n",
    "        # loop over each raw text\n",
    "        t = files[i]\n",
    "        # return unique and order list of words appeared in the raw text\n",
    "        s = set(lemmatize(t))- stop - set(string.punctuation)\n",
    "        try:\n",
    "            toks = toks | s   # append to \"toks\" set a \"s\"\n",
    "        except NameError:\n",
    "            toks = s    # if doesn't exsit, initialize it\n",
    "        for tok in s:\n",
    "            try:\n",
    "                textd[tok].append(i)\n",
    "            except KeyError:\n",
    "                textd[tok] = [i]\n",
    "    \n",
    "    return textd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/market_skills.png)\n",
    "\n",
    "Since we two are very familiar with our own majors, in our next step, we only dug into the unique skill set for statistic major.  After some research, we generated our own key words for statistic major to see which skill is the most important and basic skill we need to learn.\n",
    "\n",
    "<p>\n",
    "This is a bar plot showing the portion of jobs requiring each technique. **It can be found that “excel”, “sql”, “python”,“r” are the top four skills which are largely required by companies. In later sections, we also compared skill sets of different salary level.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/income_skills.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the next question is how can you earn more? Is there any particular skill that can boost your salary level?\n",
    "<p>\n",
    "Unfortunately, there is no quick answer to this question. We equally differentiated the job posts according to the annual salary they offer. The high salary jobs are indicated by the red bars, and the jobs in the lowest job salary level group are represented by the lightest color. The most popular skill set including r, python, and hadoop, basically the content of the 141abc course series, are all commonly required regardless of the salary level. Some other skills are required by some jobs but not the others. </p>\n",
    "<p>\n",
    "We believe there should be some correlation between the skill set and the salary level. But we did not find any particular skill that is special for the high salary level group. One possible reason is the data limitation. Not all the job posts would specify the salary level, and only about 10% of the job posts we scraped provided the salary information. The sample size is relatively small to begin with. Another hypothesis is that it may be the size of your skill set, instead of a special skill, that determines your salary level. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/violin_salary.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Job Posting Analysis: Data Scientist Vs Software engineer from Cybercoder\n",
    "\n",
    "### by Yingxi Yu, Xinyi Hou, Shengjie Shi, Hongyu Guo\n",
    "\n",
    "### Stats 141B (winter 2017) final project\n",
    "\n",
    "- webscraped cybercoder.com\n",
    "- compared data scientist job postings and software engineer\n",
    "- project at https://madscientistkris.github.io/projects/cybercoders/Project_edited_version/\n",
    "- the following is reproduced from their final project with their permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>&emsp;&emsp; \"<a href=\"https://www.cybercoders.com/\">CyberCoders</a> is one of the innovative employment search website in the state. The version of cybercoder’s website is really clear and formatted. Since their posts have no outside links like other employment search websites, we are easier to get the content of each post to construct a data frame. Also, this website focuses more on the IT related job markets, so it is perfect for us to analyze content. Additionally, this website is well organized and frequently update since we found the most of job are posted within 10 days.  \n",
    "</p>\n",
    "\n",
    "<p> &emsp;&emsp;In our project, we get the information of 109 Data Scientist and 200 Software Engineer job postings on CyberCoders through web scraping, which includes the job title, id, description, post data, salary range, preferred skills, city, and state. We compare the salary of DS and SDE, also including the comparison among different part of US. What is more, we find the need of years of experience through regular expression, the most important skills through NLP techniques. The degree required for the job and the posting dates are also topics we are interested in.\"\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/cyber_DF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/salary_dist.png)\n",
    "\n",
    "The salary comparison between Data Scientist and Software Engineer show typically higher salaries for DS (far higher than the Statistics in previous analysis).  Also we see bimodality in DS distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/east-west-salary.png)\n",
    "\n",
    "The bimodality can be explained by the differences in salaries between east and west."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/cyber_skills.png)\n",
    "\n",
    "These skills are more technical than the indeed.com Statistics skills.  They are also more reflective of the course material in 141B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/skills_word_cloud.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
